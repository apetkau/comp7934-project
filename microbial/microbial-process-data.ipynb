{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_kat_hist                            freq_k7.hist\n",
      "all_kat_hist.dist_analysis.json         \u001b[0m\u001b[01;34mimages\u001b[0m\n",
      "\u001b[01;35mall_kat_hist.png\u001b[0m                        kat.hist\n",
      "\u001b[01;34mbigsi\u001b[0m                                   kat.hist.dist_analysis.json\n",
      "\u001b[01;34mdata\u001b[0m                                    \u001b[01;35mkat.hist.png\u001b[0m\n",
      "ERR1144974                              microbial-bigsi.ipynb\n",
      "ERR1144974.dist_analysis.json           microbial-genomes.txt\n",
      "ERR1144974_kat_hist                     microbial-process-data.ipynb\n",
      "ERR1144974_kat_hist.dist_analysis.json  microbial-process-data.ipynb.bak\n",
      "\u001b[01;35mERR1144974_kat_hist.png\u001b[0m                 \u001b[01;35mo.png\u001b[0m\n",
      "\u001b[01;35mERR1144974.png\u001b[0m                          sha256\n",
      "freq_k31.hist\n"
     ]
    }
   ],
   "source": [
    "PROJECT_DIR=`git rev-parse --show-toplevel`\n",
    "cd $PROJECT_DIR/microbial\n",
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Download data\n",
    "\n",
    "As a first step, let's download all the microbial genomes in the file `microbial-genomes.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘data’: File exists\n",
      "+ fasterq-dump -o data/SRR10519619 --split-files SRR10519619\n",
      "spots read      : 2,465,304\n",
      "reads read      : 4,930,608\n",
      "reads written   : 4,930,608\n",
      "+ pigz data/SRR10519619_1.fastq data/SRR10519619_2.fastq\n",
      "+ for name in `cat microbial-genomes.txt`\n",
      "+ set -x\n",
      "+ fasterq-dump -o data/SRR10519637 --split-files SRR10519637\n",
      "spots read      : 7,316,985\n",
      "reads read      : 14,633,970\n",
      "reads written   : 14,633,970\n",
      "+ pigz data/SRR10519637_1.fastq data/SRR10519637_2.fastq\n",
      "+ for name in `cat microbial-genomes.txt`\n",
      "+ set -x\n",
      "+ fasterq-dump -o data/SRR10519620 --split-files SRR10519620\n",
      "spots read      : 3,443,404\n",
      "reads read      : 6,886,808\n",
      "reads written   : 6,886,808\n",
      "+ pigz data/SRR10519620_1.fastq data/SRR10519620_2.fastq\n",
      "+ for name in `cat microbial-genomes.txt`\n",
      "+ set -x\n",
      "+ fasterq-dump -o data/SRR10519617 --split-files SRR10519617\n",
      "spots read      : 2,681,834\n",
      "reads read      : 5,363,668\n",
      "reads written   : 5,363,668\n",
      "+ pigz data/SRR10519617_1.fastq data/SRR10519617_2.fastq\n",
      "+ for name in `cat microbial-genomes.txt`\n",
      "+ set -x\n",
      "+ fasterq-dump -o data/SRR10519616 --split-files SRR10519616\n",
      "spots read      : 2,998,025\n",
      "reads read      : 5,996,050\n",
      "reads written   : 5,996,050\n",
      "+ pigz data/SRR10519616_1.fastq data/SRR10519616_2.fastq\n",
      "+ for name in `cat microbial-genomes.txt`\n",
      "+ set -x\n",
      "+ fasterq-dump -o data/SRR10527352 --split-files SRR10527352\n",
      "spots read      : 1,638,033\n",
      "reads read      : 3,276,066\n",
      "reads written   : 3,276,066\n",
      "+ pigz data/SRR10527352_1.fastq data/SRR10527352_2.fastq\n",
      "+ for name in `cat microbial-genomes.txt`\n",
      "+ set -x\n",
      "+ fasterq-dump -o data/SRR10527353 --split-files SRR10527353\n",
      "spots read      : 1,832,803\n",
      "reads read      : 3,665,606\n",
      "reads written   : 3,665,606\n",
      "+ pigz data/SRR10527353_1.fastq data/SRR10527353_2.fastq\n",
      "+ for name in `cat microbial-genomes.txt`\n",
      "+ set -x\n",
      "+ fasterq-dump -o data/SRR10527348 --split-files SRR10527348\n",
      "spots read      : 2,281,618\n",
      "reads read      : 4,563,236\n",
      "reads written   : 4,563,236\n",
      "+ pigz data/SRR10527348_1.fastq data/SRR10527348_2.fastq\n",
      "+ for name in `cat microbial-genomes.txt`\n",
      "+ set -x\n",
      "+ fasterq-dump -o data/SRR10527351 --split-files SRR10527351\n",
      "spots read      : 1,764,396\n",
      "reads read      : 3,528,792\n",
      "reads written   : 3,528,792\n",
      "+ pigz data/SRR10527351_1.fastq data/SRR10527351_2.fastq\n",
      "+ for name in `cat microbial-genomes.txt`\n",
      "+ set -x\n",
      "+ fasterq-dump -o data/SRR10527349 --split-files SRR10527349\n",
      "spots read      : 1,649,218\n",
      "reads read      : 3,298,436\n",
      "reads written   : 3,298,436\n",
      "+ pigz data/SRR10527349_1.fastq data/SRR10527349_2.fastq\n",
      "+ for name in `cat microbial-genomes.txt`\n",
      "+ set -x\n",
      "+ fasterq-dump -o data/SRR10521984 --split-files SRR10521984\n",
      "spots read      : 1,823,660\n",
      "reads read      : 3,647,320\n",
      "reads written   : 3,647,320\n",
      "+ pigz data/SRR10521984_1.fastq data/SRR10521984_2.fastq\n",
      "+ for name in `cat microbial-genomes.txt`\n",
      "+ set -x\n",
      "+ fasterq-dump -o data/SRR10521982 --split-files SRR10521982\n",
      "spots read      : 2,542,008\n",
      "reads read      : 5,084,016\n",
      "reads written   : 5,084,016\n",
      "+ pigz data/SRR10521982_1.fastq data/SRR10521982_2.fastq\n",
      "+ for name in `cat microbial-genomes.txt`\n",
      "+ set -x\n",
      "+ fasterq-dump -o data/SRR10521983 --split-files SRR10521983\n",
      "spots read      : 2,160,344\n",
      "reads read      : 4,320,688\n",
      "reads written   : 4,320,688\n",
      "+ pigz data/SRR10521983_1.fastq data/SRR10521983_2.fastq\n",
      "+ for name in `cat microbial-genomes.txt`\n",
      "+ set -x\n",
      "+ fasterq-dump -o data/SRR10519469 --split-files SRR10519469\n",
      "spots read      : 3,124,819\n",
      "reads read      : 6,249,638\n",
      "reads written   : 6,249,638\n",
      "+ pigz data/SRR10519469_1.fastq data/SRR10519469_2.fastq\n",
      "+ for name in `cat microbial-genomes.txt`\n",
      "+ set -x\n",
      "+ fasterq-dump -o data/SRR10519468 --split-files SRR10519468\n",
      "spots read      : 4,164,792\n",
      "reads read      : 8,329,584\n",
      "reads written   : 8,329,584\n",
      "+ pigz data/SRR10519468_1.fastq data/SRR10519468_2.fastq\n",
      "+ for name in `cat microbial-genomes.txt`\n",
      "+ set -x\n",
      "+ fasterq-dump -o data/SRR10513672 --split-files SRR10513672\n",
      "spots read      : 903,007\n",
      "reads read      : 1,806,014\n",
      "reads written   : 1,806,014\n",
      "+ pigz data/SRR10513672_1.fastq data/SRR10513672_2.fastq\n",
      "+ for name in `cat microbial-genomes.txt`\n",
      "+ set -x\n",
      "+ fasterq-dump -o data/SRR10513363 --split-files SRR10513363\n",
      "spots read      : 4,180,524\n",
      "reads read      : 8,361,048\n",
      "reads written   : 8,361,048\n",
      "+ pigz data/SRR10513363_1.fastq data/SRR10513363_2.fastq\n",
      "+ for name in `cat microbial-genomes.txt`\n",
      "+ set -x\n",
      "+ fasterq-dump -o data/SRR10513326 --split-files SRR10513326\n",
      "spots read      : 1,838,335\n",
      "reads read      : 3,676,670\n",
      "reads written   : 3,676,670\n",
      "+ pigz data/SRR10513326_1.fastq data/SRR10513326_2.fastq\n",
      "+ for name in `cat microbial-genomes.txt`\n",
      "+ set -x\n",
      "+ fasterq-dump -o data/SRR10513325 --split-files SRR10513325\n",
      "spots read      : 1,203,226\n",
      "reads read      : 2,406,452\n",
      "reads written   : 2,406,452\n",
      "+ pigz data/SRR10513325_1.fastq data/SRR10513325_2.fastq\n",
      "+ for name in `cat microbial-genomes.txt`\n",
      "+ set -x\n",
      "+ fasterq-dump -o data/SRR10513328 --split-files SRR10513328\n",
      "spots read      : 1,882,971\n",
      "reads read      : 3,765,942\n",
      "reads written   : 3,765,942\n",
      "+ pigz data/SRR10513328_1.fastq data/SRR10513328_2.fastq\n",
      "+ for name in `cat microbial-genomes.txt`\n",
      "+ set -x\n",
      "+ fasterq-dump -o data/SRR10512968 --split-files SRR10512968\n",
      "spots read      : 1,123,096\n",
      "reads read      : 2,246,192\n",
      "reads written   : 2,246,192\n",
      "+ pigz data/SRR10512968_1.fastq data/SRR10512968_2.fastq\n",
      "+ for name in `cat microbial-genomes.txt`\n",
      "+ set -x\n",
      "+ fasterq-dump -o data/SRR10512964 --split-files SRR10512964\n",
      "spots read      : 999,107\n",
      "reads read      : 1,998,214\n",
      "reads written   : 1,998,214\n",
      "+ pigz data/SRR10512964_1.fastq data/SRR10512964_2.fastq\n",
      "+ for name in `cat microbial-genomes.txt`\n",
      "+ set -x\n",
      "+ fasterq-dump -o data/SRR10512965 --split-files SRR10512965\n",
      "spots read      : 543,952\n",
      "reads read      : 1,087,904\n",
      "reads written   : 1,087,904\n",
      "+ pigz data/SRR10512965_1.fastq data/SRR10512965_2.fastq\n",
      "+ for name in `cat microbial-genomes.txt`\n",
      "+ set -x\n",
      "+ fasterq-dump -o data/ERR3656018 --split-files ERR3656018\n",
      "spots read      : 2,512,546\n",
      "reads read      : 5,025,092\n",
      "reads written   : 5,025,092\n",
      "+ pigz data/ERR3656018_1.fastq data/ERR3656018_2.fastq\n",
      "+ for name in `cat microbial-genomes.txt`\n",
      "+ set -x\n",
      "+ fasterq-dump -o data/ERR3656019 --split-files ERR3656019\n",
      "spots read      : 2,458,314\n",
      "reads read      : 4,916,628\n",
      "reads written   : 4,916,628\n",
      "+ pigz data/ERR3656019_1.fastq data/ERR3656019_2.fastq\n",
      "+ for name in `cat microbial-genomes.txt`\n",
      "+ set -x\n",
      "+ fasterq-dump -o data/ERR1144974 --split-files ERR1144974\n",
      "spots read      : 18,937,653\n",
      "reads read      : 37,875,306\n",
      "reads written   : 37,875,306\n",
      "+ pigz data/ERR1144974_1.fastq data/ERR1144974_2.fastq\n",
      "+ for name in `cat microbial-genomes.txt`\n",
      "+ set -x\n",
      "+ fasterq-dump -o data/ERR1144975 --split-files ERR1144975\n",
      "spots read      : 11,701,339\n",
      "reads read      : 23,402,678\n",
      "reads written   : 23,402,678\n",
      "+ pigz data/ERR1144975_1.fastq data/ERR1144975_2.fastq\n",
      "+ for name in `cat microbial-genomes.txt`\n",
      "+ set -x\n",
      "+ fasterq-dump -o data/ERR1144976 --split-files ERR1144976\n",
      "spots read      : 9,687,071\n",
      "reads read      : 19,374,142\n",
      "reads written   : 19,374,142\n",
      "+ pigz data/ERR1144976_1.fastq data/ERR1144976_2.fastq\n",
      "+ for name in `cat microbial-genomes.txt`\n",
      "+ set -x\n",
      "+ fasterq-dump -o data/ERR1144977 --split-files ERR1144977\n",
      "spots read      : 12,010,912\n",
      "reads read      : 24,021,824\n",
      "reads written   : 24,021,824\n",
      "+ pigz data/ERR1144977_1.fastq data/ERR1144977_2.fastq\n",
      "+ for name in `cat microbial-genomes.txt`\n",
      "+ set -x\n",
      "+ fasterq-dump -o data/ERR1144978 --split-files ERR1144978\n",
      "spots read      : 11,161,674\n",
      "reads read      : 22,323,348\n",
      "reads written   : 22,323,348\n",
      "+ pigz data/ERR1144978_1.fastq data/ERR1144978_2.fastq\n",
      "+ for name in `cat microbial-genomes.txt`\n",
      "+ set -x\n",
      "+ fasterq-dump -o data/SRR8088185 --split-files SRR8088185\n",
      "spots read      : 762,692\n",
      "reads read      : 1,525,384\n",
      "reads written   : 1,525,384\n",
      "+ pigz data/SRR8088185_1.fastq data/SRR8088185_2.fastq\n",
      "+ for name in `cat microbial-genomes.txt`\n",
      "+ set -x\n",
      "+ fasterq-dump -o data/SRR8088181 --split-files SRR8088181\n",
      "spots read      : 715,282\n",
      "reads read      : 1,430,564\n",
      "reads written   : 1,430,564\n",
      "+ pigz data/SRR8088181_1.fastq data/SRR8088181_2.fastq\n",
      "+ for name in `cat microbial-genomes.txt`\n",
      "+ set -x\n",
      "+ fasterq-dump -o data/SRR8088184 --split-files SRR8088184\n",
      "spots read      : 530,412\n",
      "reads read      : 1,060,824\n",
      "reads written   : 1,060,824\n",
      "+ pigz data/SRR8088184_1.fastq data/SRR8088184_2.fastq\n",
      "+ for name in `cat microbial-genomes.txt`\n",
      "+ set -x\n",
      "+ fasterq-dump -o data/SRR8088182 --split-files SRR8088182\n",
      "spots read      : 586,288\n",
      "reads read      : 1,172,576\n",
      "reads written   : 1,172,576\n",
      "+ pigz data/SRR8088182_1.fastq data/SRR8088182_2.fastq\n",
      "+ for name in `cat microbial-genomes.txt`\n",
      "+ set -x\n",
      "+ fasterq-dump -o data/SRR8088183 --split-files SRR8088183\n",
      "spots read      : 615,101\n",
      "reads read      : 1,230,202\n",
      "reads written   : 1,230,202\n",
      "+ pigz data/SRR8088183_1.fastq data/SRR8088183_2.fastq\n",
      "+ for name in `cat microbial-genomes.txt`\n",
      "+ set -x\n",
      "+ fasterq-dump -o data/ERR3656013 --split-files ERR3656013\n",
      "spots read      : 2,204,984\n",
      "reads read      : 4,409,968\n",
      "reads written   : 4,409,968\n",
      "+ pigz data/ERR3656013_1.fastq data/ERR3656013_2.fastq\n",
      "+ for name in `cat microbial-genomes.txt`\n",
      "+ set -x\n",
      "+ fasterq-dump -o data/ERR3656015 --split-files ERR3656015\n",
      "spots read      : 1,876,686\n",
      "reads read      : 3,753,372\n",
      "reads written   : 3,753,372\n",
      "+ pigz data/ERR3656015_1.fastq data/ERR3656015_2.fastq\n",
      "+ for name in `cat microbial-genomes.txt`\n",
      "+ set -x\n",
      "+ fasterq-dump -o data/ERR3656010 --split-files ERR3656010\n",
      "spots read      : 2,572,532\n",
      "reads read      : 5,145,064\n",
      "reads written   : 5,145,064\n",
      "+ pigz data/ERR3656010_1.fastq data/ERR3656010_2.fastq\n",
      "+ for name in `cat microbial-genomes.txt`\n",
      "+ set -x\n",
      "+ fasterq-dump -o data/ERR3656012 --split-files ERR3656012\n",
      "spots read      : 1,949,899\n",
      "reads read      : 3,899,798\n",
      "reads written   : 3,899,798\n",
      "+ pigz data/ERR3656012_1.fastq data/ERR3656012_2.fastq\n",
      "+ for name in `cat microbial-genomes.txt`\n",
      "+ set -x\n",
      "+ fasterq-dump -o data/ERR3656004 --split-files ERR3656004\n",
      "spots read      : 2,285,720\n",
      "reads read      : 4,571,440\n",
      "reads written   : 4,571,440\n",
      "+ pigz data/ERR3656004_1.fastq data/ERR3656004_2.fastq\n",
      "+ for name in `cat microbial-genomes.txt`\n",
      "+ set -x\n",
      "+ fasterq-dump -o data/ERR3656002 --split-files ERR3656002\n",
      "spots read      : 3,135,157\n",
      "reads read      : 6,270,314\n",
      "reads written   : 6,270,314\n",
      "+ pigz data/ERR3656002_1.fastq data/ERR3656002_2.fastq\n",
      "+ for name in `cat microbial-genomes.txt`\n",
      "+ set -x\n",
      "+ fasterq-dump -o data/ERR3655998 --split-files ERR3655998\n",
      "spots read      : 2,861,433\n",
      "reads read      : 5,722,866\n",
      "reads written   : 5,722,866\n",
      "+ pigz data/ERR3655998_1.fastq data/ERR3655998_2.fastq\n",
      "+ for name in `cat microbial-genomes.txt`\n",
      "+ set -x\n",
      "+ fasterq-dump -o data/ERR3655996 --split-files ERR3655996\n",
      "spots read      : 2,794,004\n",
      "reads read      : 5,588,008\n",
      "reads written   : 5,588,008\n",
      "+ pigz data/ERR3655996_1.fastq data/ERR3655996_2.fastq\n",
      "+ for name in `cat microbial-genomes.txt`\n",
      "+ set -x\n",
      "+ fasterq-dump -o data/ERR3655994 --split-files ERR3655994\n",
      "spots read      : 2,550,255\n",
      "reads read      : 5,100,510\n",
      "reads written   : 5,100,510\n",
      "+ pigz data/ERR3655994_1.fastq data/ERR3655994_2.fastq\n",
      "+ for name in `cat microbial-genomes.txt`\n",
      "+ set -x\n",
      "+ fasterq-dump -o data/ERR3655992 --split-files ERR3655992\n",
      "spots read      : 2,470,001\n",
      "reads read      : 4,940,002\n",
      "reads written   : 4,940,002\n",
      "+ pigz data/ERR3655992_1.fastq data/ERR3655992_2.fastq\n",
      "+ for name in `cat microbial-genomes.txt`\n",
      "+ set -x\n",
      "+ fasterq-dump -o data/SRR10298905 --split-files SRR10298905\n",
      "spots read      : 631,108\n",
      "reads read      : 1,262,216\n",
      "reads written   : 1,262,216\n",
      "+ pigz data/SRR10298905_1.fastq data/SRR10298905_2.fastq\n",
      "+ for name in `cat microbial-genomes.txt`\n",
      "+ set -x\n",
      "+ fasterq-dump -o data/SRR10298906 --split-files SRR10298906\n",
      "spots read      : 586,439\n",
      "reads read      : 1,172,878\n",
      "reads written   : 1,172,878\n",
      "+ pigz data/SRR10298906_1.fastq data/SRR10298906_2.fastq\n",
      "+ for name in `cat microbial-genomes.txt`\n",
      "+ set -x\n",
      "+ fasterq-dump -o data/SRR10298907 --split-files SRR10298907\n",
      "spots read      : 693,588\n",
      "reads read      : 1,387,176\n",
      "reads written   : 1,387,176\n",
      "+ pigz data/SRR10298907_1.fastq data/SRR10298907_2.fastq\n",
      "+ for name in `cat microbial-genomes.txt`\n",
      "+ set -x\n",
      "+ fasterq-dump -o data/SRR10298903 --split-files SRR10298903\n",
      "spots read      : 447,914\n",
      "reads read      : 895,828\n",
      "reads written   : 895,828\n",
      "+ pigz data/SRR10298903_1.fastq data/SRR10298903_2.fastq\n",
      "+ for name in `cat microbial-genomes.txt`\n",
      "+ set -x\n",
      "+ fasterq-dump -o data/SRR10298904 --split-files SRR10298904\n",
      "spots read      : 311,339\n",
      "reads read      : 622,678\n",
      "reads written   : 622,678\n",
      "+ pigz data/SRR10298904_1.fastq data/SRR10298904_2.fastq\n",
      "+ set +x\n"
     ]
    }
   ],
   "source": [
    "mkdir data\n",
    "\n",
    "for name in `cat microbial-genomes.txt`;\n",
    "do\n",
    "    set -x\n",
    "    fasterq-dump -o data/${name} --split-files ${name}\n",
    "    pigz data/${name}*\n",
    "done\n",
    "set +x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;31mERR1144974_1.fastq.gz\u001b[0m  \u001b[01;31mSRR10298903_1.fastq.gz\u001b[0m  \u001b[01;31mSRR10519619_1.fastq.gz\u001b[0m\n",
      "\u001b[01;31mERR1144974_2.fastq.gz\u001b[0m  \u001b[01;31mSRR10298903_2.fastq.gz\u001b[0m  \u001b[01;31mSRR10519619_2.fastq.gz\u001b[0m\n",
      "\u001b[01;31mERR1144975_1.fastq.gz\u001b[0m  \u001b[01;31mSRR10298904_1.fastq.gz\u001b[0m  \u001b[01;31mSRR10519620_1.fastq.gz\u001b[0m\n",
      "\u001b[01;31mERR1144975_2.fastq.gz\u001b[0m  \u001b[01;31mSRR10298904_2.fastq.gz\u001b[0m  \u001b[01;31mSRR10519620_2.fastq.gz\u001b[0m\n",
      "\u001b[01;31mERR1144976_1.fastq.gz\u001b[0m  \u001b[01;31mSRR10298905_1.fastq.gz\u001b[0m  \u001b[01;31mSRR10519637_1.fastq.gz\u001b[0m\n",
      "\u001b[01;31mERR1144976_2.fastq.gz\u001b[0m  \u001b[01;31mSRR10298905_2.fastq.gz\u001b[0m  \u001b[01;31mSRR10519637_2.fastq.gz\u001b[0m\n",
      "\u001b[01;31mERR1144977_1.fastq.gz\u001b[0m  \u001b[01;31mSRR10298906_1.fastq.gz\u001b[0m  \u001b[01;31mSRR10521982_1.fastq.gz\u001b[0m\n",
      "\u001b[01;31mERR1144977_2.fastq.gz\u001b[0m  \u001b[01;31mSRR10298906_2.fastq.gz\u001b[0m  \u001b[01;31mSRR10521982_2.fastq.gz\u001b[0m\n",
      "\u001b[01;31mERR1144978_1.fastq.gz\u001b[0m  \u001b[01;31mSRR10298907_1.fastq.gz\u001b[0m  \u001b[01;31mSRR10521983_1.fastq.gz\u001b[0m\n",
      "\u001b[01;31mERR1144978_2.fastq.gz\u001b[0m  \u001b[01;31mSRR10298907_2.fastq.gz\u001b[0m  \u001b[01;31mSRR10521983_2.fastq.gz\u001b[0m\n",
      "\u001b[01;31mERR3655992_1.fastq.gz\u001b[0m  \u001b[01;31mSRR10512964_1.fastq.gz\u001b[0m  \u001b[01;31mSRR10521984_1.fastq.gz\u001b[0m\n",
      "\u001b[01;31mERR3655992_2.fastq.gz\u001b[0m  \u001b[01;31mSRR10512964_2.fastq.gz\u001b[0m  \u001b[01;31mSRR10521984_2.fastq.gz\u001b[0m\n",
      "\u001b[01;31mERR3655994_1.fastq.gz\u001b[0m  \u001b[01;31mSRR10512965_1.fastq.gz\u001b[0m  \u001b[01;31mSRR10527348_1.fastq.gz\u001b[0m\n",
      "\u001b[01;31mERR3655994_2.fastq.gz\u001b[0m  \u001b[01;31mSRR10512965_2.fastq.gz\u001b[0m  \u001b[01;31mSRR10527348_2.fastq.gz\u001b[0m\n",
      "\u001b[01;31mERR3655996_1.fastq.gz\u001b[0m  \u001b[01;31mSRR10512968_1.fastq.gz\u001b[0m  \u001b[01;31mSRR10527349_1.fastq.gz\u001b[0m\n",
      "\u001b[01;31mERR3655996_2.fastq.gz\u001b[0m  \u001b[01;31mSRR10512968_2.fastq.gz\u001b[0m  \u001b[01;31mSRR10527349_2.fastq.gz\u001b[0m\n",
      "\u001b[01;31mERR3655998_1.fastq.gz\u001b[0m  \u001b[01;31mSRR10513325_1.fastq.gz\u001b[0m  \u001b[01;31mSRR10527351_1.fastq.gz\u001b[0m\n",
      "\u001b[01;31mERR3655998_2.fastq.gz\u001b[0m  \u001b[01;31mSRR10513325_2.fastq.gz\u001b[0m  \u001b[01;31mSRR10527351_2.fastq.gz\u001b[0m\n",
      "\u001b[01;31mERR3656002_1.fastq.gz\u001b[0m  \u001b[01;31mSRR10513326_1.fastq.gz\u001b[0m  \u001b[01;31mSRR10527352_1.fastq.gz\u001b[0m\n",
      "\u001b[01;31mERR3656002_2.fastq.gz\u001b[0m  \u001b[01;31mSRR10513326_2.fastq.gz\u001b[0m  \u001b[01;31mSRR10527352_2.fastq.gz\u001b[0m\n",
      "\u001b[01;31mERR3656004_1.fastq.gz\u001b[0m  \u001b[01;31mSRR10513328_1.fastq.gz\u001b[0m  \u001b[01;31mSRR10527353_1.fastq.gz\u001b[0m\n",
      "\u001b[01;31mERR3656004_2.fastq.gz\u001b[0m  \u001b[01;31mSRR10513328_2.fastq.gz\u001b[0m  \u001b[01;31mSRR10527353_2.fastq.gz\u001b[0m\n",
      "\u001b[01;31mERR3656010_1.fastq.gz\u001b[0m  \u001b[01;31mSRR10513363_1.fastq.gz\u001b[0m  \u001b[01;31mSRR8088181_1.fastq.gz\u001b[0m\n",
      "\u001b[01;31mERR3656010_2.fastq.gz\u001b[0m  \u001b[01;31mSRR10513363_2.fastq.gz\u001b[0m  \u001b[01;31mSRR8088181_2.fastq.gz\u001b[0m\n",
      "\u001b[01;31mERR3656012_1.fastq.gz\u001b[0m  \u001b[01;31mSRR10513672_1.fastq.gz\u001b[0m  \u001b[01;31mSRR8088182_1.fastq.gz\u001b[0m\n",
      "\u001b[01;31mERR3656012_2.fastq.gz\u001b[0m  \u001b[01;31mSRR10513672_2.fastq.gz\u001b[0m  \u001b[01;31mSRR8088182_2.fastq.gz\u001b[0m\n",
      "\u001b[01;31mERR3656013_1.fastq.gz\u001b[0m  \u001b[01;31mSRR10519468_1.fastq.gz\u001b[0m  \u001b[01;31mSRR8088183_1.fastq.gz\u001b[0m\n",
      "\u001b[01;31mERR3656013_2.fastq.gz\u001b[0m  \u001b[01;31mSRR10519468_2.fastq.gz\u001b[0m  \u001b[01;31mSRR8088183_2.fastq.gz\u001b[0m\n",
      "\u001b[01;31mERR3656015_1.fastq.gz\u001b[0m  \u001b[01;31mSRR10519469_1.fastq.gz\u001b[0m  \u001b[01;31mSRR8088184_1.fastq.gz\u001b[0m\n",
      "\u001b[01;31mERR3656015_2.fastq.gz\u001b[0m  \u001b[01;31mSRR10519469_2.fastq.gz\u001b[0m  \u001b[01;31mSRR8088184_2.fastq.gz\u001b[0m\n",
      "\u001b[01;31mERR3656018_1.fastq.gz\u001b[0m  \u001b[01;31mSRR10519616_1.fastq.gz\u001b[0m  \u001b[01;31mSRR8088185_1.fastq.gz\u001b[0m\n",
      "\u001b[01;31mERR3656018_2.fastq.gz\u001b[0m  \u001b[01;31mSRR10519616_2.fastq.gz\u001b[0m  \u001b[01;31mSRR8088185_2.fastq.gz\u001b[0m\n",
      "\u001b[01;31mERR3656019_1.fastq.gz\u001b[0m  \u001b[01;31mSRR10519617_1.fastq.gz\u001b[0m\n",
      "\u001b[01;31mERR3656019_2.fastq.gz\u001b[0m  \u001b[01;31mSRR10519617_2.fastq.gz\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20G\tdata\n"
     ]
    }
   ],
   "source": [
    "du -sh data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome. We've downloaded and compressed all the microbial genomes.\n",
    "\n",
    "# Step 2: Cleaning reads\n",
    "\n",
    "Now that we have data downloaded, let's subsample our data (and mask low-quality bases) using the software [seqtk](https://github.com/lh3/seqtk).\n",
    "\n",
    "Let's first set some basic environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "threads=48"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's clean and subsample the reads down to a max of 1 million per each read pair (since some files have a lot of reads)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘data/subsample’: File exists\n",
      "Working on ERR1144974\n",
      "Working on ERR1144975\n",
      "Working on ERR1144976\n",
      "Working on ERR1144977\n",
      "Working on ERR1144978\n",
      "Working on ERR3655992\n",
      "Working on ERR3655994\n",
      "Working on ERR3655996\n",
      "Working on ERR3655998\n",
      "Working on ERR3656002\n",
      "Working on ERR3656004\n",
      "Working on ERR3656010\n",
      "Working on ERR3656012\n",
      "Working on ERR3656013\n",
      "Working on ERR3656015\n",
      "Working on ERR3656018\n",
      "Working on ERR3656019\n",
      "Working on SRR10298903\n",
      "Working on SRR10298904\n",
      "Working on SRR10298905\n",
      "Working on SRR10298906\n",
      "Working on SRR10298907\n",
      "Working on SRR10512964\n",
      "Working on SRR10512965\n",
      "Working on SRR10512968\n",
      "Working on SRR10513325\n",
      "Working on SRR10513326\n",
      "Working on SRR10513328\n",
      "Working on SRR10513363\n",
      "Working on SRR10513672\n",
      "Working on SRR10519468\n",
      "Working on SRR10519469\n",
      "Working on SRR10519616\n",
      "Working on SRR10519617\n",
      "Working on SRR10519619\n",
      "Working on SRR10519620\n",
      "Working on SRR10519637\n",
      "Working on SRR10521982\n",
      "Working on SRR10521983\n",
      "Working on SRR10521984\n",
      "Working on SRR10527348\n",
      "Working on SRR10527349\n",
      "Working on SRR10527351\n",
      "Working on SRR10527352\n",
      "Working on SRR10527353\n",
      "Working on SRR8088181\n",
      "Working on SRR8088182\n",
      "Working on SRR8088183\n",
      "Working on SRR8088184\n",
      "Working on SRR8088185\n"
     ]
    }
   ],
   "source": [
    "mkdir data/subsample\n",
    "\n",
    "max_reads=1000000\n",
    "\n",
    "for file in data/*_1.fastq.gz\n",
    "do\n",
    "    name=`basename $file _1.fastq.gz`\n",
    "    \n",
    "    input1=data/${name}_1.fastq.gz\n",
    "    input2=data/${name}_2.fastq.gz\n",
    "    output1=data/subsample/${name}_1.fastq.gz\n",
    "    output2=data/subsample/${name}_2.fastq.gz\n",
    "    \n",
    "    echo \"Working on ${name}\"\n",
    "        \n",
    "    conda run --name seqtk seqtk sample -s 41 $input1 ${max_reads} | pigz --fast -c -p ${threads} > ${output1}\n",
    "    conda run --name seqtk seqtk sample -s 41 $input2 ${max_reads} | pigz --fast -c -p ${threads} > ${output2}\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.6G\tdata/subsample/\n"
     ]
    }
   ],
   "source": [
    "du -sh data/subsample/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome. Looks like we've cut our total data size by half."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Examining data\n",
    "\n",
    "Now, let's use the software [dashing](https://github.com/dnbaker/dashing) (version `0.4.0`) to estimate the total number of unique k-mers in our dataset.\n",
    "\n",
    "This sofware must be downloaded and placed in your `PATH`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dashing version: v0.4.0-5-g9c13\n",
      "Dashing version: v0.4.0-5-g9c13\n",
      "Dashing version: v0.4.0-5-g9c13\n",
      "[int bns::hll_main(int, char**)] Processing 100 paths with 32 threads\n",
      "Estimated number of unique exact matches: 1691459836.000000\n"
     ]
    }
   ],
   "source": [
    "dashing_s512 --version\n",
    "dashing_s512 hll -k 31 -p 32 data/*.fastq.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result tells us that among all our genomes, we have appromximetly 1.7*10^9 (1.7 billion) unique 31-mers in our dataset.\n",
    "\n",
    "Let's normalize this value based on the number of bases in our data to get a value of **unique k-mers/hundred bp**.\n",
    "\n",
    "First, we have to count all the basepairs in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reads: 307223608\n",
      "Number of bases in reads: 35864044717\n"
     ]
    }
   ],
   "source": [
    "# Code derived from https://bioinformatics.stackexchange.com/a/966\n",
    "pigz -dc data/*.fastq.gz | awk 'NR%4==2{c++; l+=length($0)}\n",
    "          END{\n",
    "                print \"Number of reads: \"c;\n",
    "                print \"Number of bases in reads: \"l\n",
    "              }'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we have to convert to our normalized value **unique k-mers/hundred bp**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.71631086049317564484\n"
     ]
    }
   ],
   "source": [
    "KMERS=1691459836\n",
    "BP=35864044717\n",
    "echo \"${KMERS}/(${BP}/100)\" | bc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome. This dataset has about 4.7 unique 31-mers/100 bp."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now look at a k-mer histogram using [kat](https://kat.readthedocs.io). This can be installed from bioconda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmer Analysis Toolkit (KAT) V2.4.2\n",
      "\n",
      "Running KAT in HIST mode\n",
      "------------------------\n",
      "\n",
      "Input 1 is a sequence file.  Counting kmers for input 1 (data/ERR1144974_1.fastq.gz data/ERR1144974_2.fastq.gz) ... done.  Time taken: 37.9s\n",
      "\n",
      "Bining kmers ... done.  Time taken: 0.3s\n",
      "\n",
      "Merging counts ... done.  Time taken: 0.0s\n",
      "\n",
      "Saving results to disk ... done.  Time taken: 0.0s\n",
      "\n",
      "Creating plot ... done.  Time taken: 0.8s\n",
      "\n",
      "Analysing peaks\n",
      "---------------\n",
      "\n",
      "Analysing distributions for: ERR1144974_kat_hist ... done.  Time taken:  0.2s\n",
      "\n",
      "K-mer frequency spectra statistics\n",
      "----------------------------------\n",
      "K-value used: 31\n",
      "Peaks in analysis: 1\n",
      "Global minima @ Frequency=36x (797)\n",
      "Global maxima @ Frequency=499x (16869)\n",
      "Overall mean k-mer frequency: 250x\n",
      "\n",
      "  Index    Left    Mean    Right    StdDev    Max    Volume  Description\n",
      "-------  ------  ------  -------  --------  -----  --------  -------------\n",
      "      1       3     251      499       124    450    134040  1/2X\n",
      "\n",
      "Calculating genome statistics\n",
      "-----------------------------\n",
      "Assuming that homozygous peak is the largest in the spectra with frequency of: 250x\n",
      "Homozygous peak index: 0\n",
      "CAUTION: the following estimates are based on having a clean spectra and having identified the correct homozygous peak!\n",
      "Estimated genome size: 0.00 Mbp\n",
      "\n",
      "Creating plots\n",
      "--------------\n",
      "\n",
      "Plotting K-mer frequency distributions ... done.  Saved to: None\n",
      "\n",
      "\n",
      "KAT HIST completed.\n",
      "Total runtime: 39.4s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conda run --name kat kat hist -o ERR1144974_kat_hist -t 32 -m 31 data/ERR1144974*.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome. We'll have to resize this image, so let's use `convert` from imagemagick to resize so we can display inline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mdata\u001b[0m                                    \u001b[01;34mimages\u001b[0m\n",
      "ERR1144974                              kat.hist\n",
      "ERR1144974.dist_analysis.json           kat.hist.dist_analysis.json\n",
      "ERR1144974_kat_hist                     \u001b[01;35mkat.hist.png\u001b[0m\n",
      "ERR1144974_kat_hist.dist_analysis.json  microbial-genomes.txt\n",
      "\u001b[01;35mERR1144974_kat_hist.png\u001b[0m                 \u001b[01;35mo.png\u001b[0m\n",
      "\u001b[01;35mERR1144974.png\u001b[0m                          process-data.ipynb\n"
     ]
    }
   ],
   "source": [
    "ls\n",
    "convert ERR1144974_kat_hist.png -resize 600x images/ERR1144974_kat_hist.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final k-mer distribution is:\n",
    "\n",
    "![ERR1144974_kat_hist.png](images/ERR1144974_kat_hist.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay. Now let's try to look at a k-mer historygram over all files.\n",
    "\n",
    "We first have to concatenate all files together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir data/all\n",
    "cat data/*.fastq.gz > data/all/all.fastq.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's create a histogram over all this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmer Analysis Toolkit (KAT) V2.4.2\n",
      "\n",
      "Running KAT in HIST mode\n",
      "------------------------\n",
      "\n",
      "Input 1 is a sequence file.  Counting kmers for input 1 (data/all/all.fastq.gz) ...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size... success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      "\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size... success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      "\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size... success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      "\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size...\n",
      "Warning: Specified hash size insufficent - attempting to double hash size... success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " success!\n",
      " done.  Time taken: 856.2s\n",
      "\n",
      "Bining kmers ... done.  Time taken: 17.5s\n",
      "\n",
      "Merging counts ... done.  Time taken: 0.0s\n",
      "\n",
      "Saving results to disk ... done.  Time taken: 0.0s\n",
      "\n",
      "Creating plot ... done.  Time taken: 1.0s\n",
      "\n",
      "Analysing peaks\n",
      "---------------\n",
      "\n",
      "Analysing distributions for: all_kat_hist ... done.  Time taken:  5.2s\n",
      "\n",
      "K-mer frequency spectra statistics\n",
      "----------------------------------\n",
      "K-value used: 31\n",
      "Peaks in analysis: 5\n",
      "Global minima @ Frequency=27x (97168)\n",
      "Global maxima @ Frequency=73x (216915)\n",
      "Overall mean k-mer frequency: 235x\n",
      "\n",
      "  Index    Left    Mean    Right    StdDev     Max    Volume  Description\n",
      "-------  ------  ------  -------  --------  ------  --------  -------------\n",
      "      1   12.25   38       63.75     12.88    8370    269800  1/2X\n",
      "      2   14.93   74.01   133.1      29.54  173898  12802180  1X\n",
      "      3   16.97  144      271.03     63.51   36427   5733092  2X\n",
      "      4   26.08  292      557.92    132.96   53575  16548364  4X\n",
      "      5   28.94  365      701.06    168.03   40648  13242201  5X\n",
      "\n",
      "Calculating genome statistics\n",
      "-----------------------------\n",
      "Assuming that homozygous peak is the largest in the spectra with frequency of: 74x\n",
      "Homozygous peak index: 2\n",
      "CAUTION: the following estimates are based on having a clean spectra and having identified the correct homozygous peak!\n",
      "Estimated genome size: 127.02 Mbp\n",
      "Estimated heterozygous rate: 0.01%\n",
      "\n",
      "Creating plots\n",
      "--------------\n",
      "\n",
      "Plotting K-mer frequency distributions ... done.  Saved to: None\n",
      "\n",
      "\n",
      "KAT HIST completed.\n",
      "Total runtime: 880.3s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conda run --name kat kat hist -o all_kat_hist -t 32 -m 31 data/all/all.fastq.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hooray, it finished :). Now let's resize the image and remove the 20GB all fastq file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_kat_hist                            \u001b[0m\u001b[01;35mERR1144974.png\u001b[0m\n",
      "all_kat_hist.dist_analysis.json         \u001b[01;34mimages\u001b[0m\n",
      "\u001b[01;35mall_kat_hist.png\u001b[0m                        kat.hist\n",
      "\u001b[01;34mdata\u001b[0m                                    kat.hist.dist_analysis.json\n",
      "ERR1144974                              \u001b[01;35mkat.hist.png\u001b[0m\n",
      "ERR1144974.dist_analysis.json           microbial-genomes.txt\n",
      "ERR1144974_kat_hist                     \u001b[01;35mo.png\u001b[0m\n",
      "ERR1144974_kat_hist.dist_analysis.json  process-data.ipynb\n",
      "\u001b[01;35mERR1144974_kat_hist.png\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ls\n",
    "convert all_kat_hist.png -resize 600x images/all_kat_hist.png\n",
    "rm data/all/all.fastq.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![all_kat_hist.png](images/all_kat_hist.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Huh, interesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Parsing command line failed with exception: The required input directory tmp.squeakr does not seem to exist.\n",
      "\n",
      "\n",
      "SYNOPSIS\n",
      "        squeakr count [-e] -k <k-size> [-c <cutoff>] [-n] [-s <log-slots>] [-t <num-threads>] -o <out-file> <files>... [-v]\n",
      "        squeakr query -f <squeakr-file> -q <query-file> -o <output-file> [-v]\n",
      "        squeakr inner_prod <first-input> <second-input> [-v]\n",
      "        squeakr list -f <squeakr-file> -o <output-file> [-v]\n",
      "        squeakr info -f <squeakr-file> [-v]\n",
      "        squeakr help [-v]\n",
      "\n",
      "OPTIONS\n",
      "        -e, --exact squeakr-exact (default is Squeakr approximate)\n",
      "        <k-size>    length of k-mers to count\n",
      "        <cutoff>    only output k-mers with count greater than or equal to cutoff (default = 1)\n",
      "\n",
      "        -n, --no-counts\n",
      "                    only output k-mers and no counts (default = false)\n",
      "\n",
      "        <log-slots> log of number of slots in the CQF. (Size argument is only optional when numthreads is exactly 1.)\n",
      "\n",
      "        <num-threads>\n",
      "                    number of threads to use to count (default = number of hardware threads)\n",
      "\n",
      "        <out-file>  file in which output should be written\n",
      "        <files>...  list of files to be counted (supported files: fastq and compressed gzip or bzip2 fastq files)\n",
      "\n",
      "        <squeakr-file>\n",
      "                    input squeakr file\n",
      "\n",
      "        <query-file>\n",
      "                    input query file\n",
      "\n",
      "        <output-file>\n",
      "                    output file\n",
      "\n",
      "        <first-input>\n",
      "                    first input squeakr file\n",
      "\n",
      "        <second-input>\n",
      "                    second input squeakr file\n",
      "\n",
      "        <squeakr-file>\n",
      "                    input squeakr file\n",
      "\n",
      "        <output-file>\n",
      "                    output file\n",
      "\n",
      "        <squeakr-file>\n",
      "                    input squeakr file\n",
      "\n",
      "        -v, --version\n",
      "                    show version\n",
      "ERROR conda.cli.main_run:execute(39): Subprocess for 'conda run ['squeakr', 'count', '-e', '-k', '31', '-s', '20', '-t', '24', '-o', 'tmp.squeakr', 'data/ERR1144974_1.fastq.gz']' command failed.  Stderr was:\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "conda run --name squeakr squeakr count -e -k 31 -s 20 -t 24 -o tmp.squeakr data/ERR1144974_1.fastq.gz"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash [conda env:comp7934-project] *",
   "language": "bash",
   "name": "conda-env-comp7934-project-bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
