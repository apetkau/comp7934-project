{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Break into kmers with Jellyfish\n",
    "\n",
    "Both BIGSI and HowDeSBT operate on k-mers (of some size k), which are inserted into Bloom filters. While each program can take a variety of input files (and HowDeSBT can count k-mers itself), in order to measure performance we wish to start with a common set of inputs. So, we will break our data into kmers with the program [jellyfish](https://github.com/gmarcais/Jellyfish) ahead of time.\n",
    "\n",
    "First, let's setup some directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir=data-downsampled\n",
    "kmer_dir=kmer-downsampled\n",
    "kmer_counts_dir=kmer-counts-jellyfish\n",
    "kmers_input_sizes=\"9 15 21 25 29 31\"\n",
    "\n",
    "jobs=50\n",
    "threads=4\n",
    "\n",
    "PROJECT_DIR=`git rev-parse --show-toplevel`\n",
    "cd $PROJECT_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code given below assumes you have the following [conda](https://docs.conda.io/en/latest/) environments setup to install [jellyfish](https://github.com/gmarcais/Jellyfish). This can be done with.\n",
    "\n",
    "```bash\n",
    "conda create --name jellyfish jellyfish\n",
    "```\n",
    "\n",
    "Let's verify these commands exist (and verify versions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda run --name jellyfish jellyfish --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once this step is complete, we need to figure out the maximum number of kmers for our 3 datasets (for passing to `jellyfish` to set the hash size). Let's define a bash function for this.\n",
    "\n",
    "## Find max data kmer cardinality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purpose: Gets max kmer cardinality estimates on sequence reads.\n",
    "# Args:\n",
    "#      input_dir: The input directory containing all the kmer counts.\n",
    "#      kmer_size: The kmer_size to find the max.\n",
    "# Output: Prints the the maximum kmer count for the kmer size\n",
    "#         in this directory (files named like `kmer-9.tsv`).\n",
    "get_max_kmer_cardinality() {\n",
    "    input_dir=$1\n",
    "    kmer_size=$2\n",
    "    \n",
    "    cut -f 2 \"${input_dir}/kmer-${kmer_size}.tsv\" | sort -n | tail -n 1 | awk '{print int($1+0.5)}'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test this code out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_max_kmer_cardinality \"microbial/${kmer_dir}\" \"31\"\n",
    "get_max_kmer_cardinality \"human/${kmer_dir}\" \"31\"\n",
    "get_max_kmer_cardinality \"metagenomics/${kmer_dir}\" \"31\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great. Now that we have this setup, we can move to defining a function to count and produce a list of all kmers in the dataset using `jellyfish`.\n",
    "\n",
    "## Bash jellyfish kmer count function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purpose: Runs jellyfish on sequence reads to count kmers.\n",
    "# Args:\n",
    "#      type_dir: The input type directory (e.g., microbial,)\n",
    "#      output_dir: A directory to save the jellyfish output into.\n",
    "#      kmer_sizes: The kmer_sizes to run (separated by spaces).\n",
    "# Output: Jellyfish kmer counts in the passed output directory.\n",
    "run_jellyfish() {\n",
    "    type_dir=$1\n",
    "    output_dir=$2\n",
    "    kmer_sizes=$3\n",
    "    \n",
    "    input_dir=${type_dir}/${data_dir}\n",
    "    \n",
    "    rm -rf ${output_dir}\n",
    "    mkdir ${output_dir}\n",
    "    \n",
    "    before=`date +%s`\n",
    "    \n",
    "    for kmer_size in ${kmer_sizes}\n",
    "    do\n",
    "        # Find max kmers\n",
    "        max_kmer=`get_max_kmer_cardinality \"${type_dir}/${kmer_dir}\" \"${kmer_size}\"`\n",
    "        \n",
    "        # Hash size is 10x the max kmers in dataset.\n",
    "        #hash_size=`echo \"10*${max_kmer}\" | bc`\n",
    "        \n",
    "        output_dir_kmer=${output_dir}/${kmer_size}\n",
    "        mkdir ${output_dir_kmer}\n",
    "        \n",
    "        commands_file=`mktemp`\n",
    "    \n",
    "        # Let's generate a list of commands to a temporary ${commands_file}\n",
    "        for file in ${input_dir}/*.fastq.gz\n",
    "        do\n",
    "            accession=`basename ${file} .fastq.gz`\n",
    "\n",
    "            jellyfish_out=${output_dir_kmer}/${accession}.jf\n",
    "            jellyfish_log=${output_dir_kmer}/jellyfish.count.${accession}.log\n",
    "                        \n",
    "            kmer_counts_out=${output_dir_kmer}/${accession}.kmer.gz\n",
    "            kmer_counts_log=${output_dir_kmer}/jellyfish.dump.${accession}.log\n",
    "        \n",
    "            # Command to generate a list of kmers with jellyfish and dump to a text file (gzipped)\n",
    "            command=\"/usr/bin/time -v jellyfish count --size ${max_kmer} --threads ${threads} --mer-len ${kmer_size} --output ${jellyfish_out} \\\n",
    "                --canonical <(gzip -d --stdout ${file}) 2> ${jellyfish_log}.err 1> ${jellyfish_log} && \\\n",
    "                /usr/bin/time -v jellyfish dump --column --tab ${jellyfish_out} 2> ${kmer_counts_log}.err | gzip --stdout > ${kmer_counts_out} && \\\n",
    "                rm ${jellyfish_out}\"\n",
    "            echo ${command} >> ${commands_file}\n",
    "        done\n",
    "        \n",
    "        # Now, let's execute those commands in parallel\n",
    "        printf \"Will execute the following commands from [%s]\\n\" ${commands_file}\n",
    "        cat ${commands_file}\n",
    "        \n",
    "        command=\"parallel -j ${jobs} -a ${commands_file}\"\n",
    "        echo $command\n",
    "        ${command}\n",
    "    done\n",
    "        \n",
    "    after=`date +%s`\n",
    "    minutes=`echo \"(${after}-${before})/60\" | bc -l`\n",
    "    printf \"Done. Took %0.2f minutes.\" ${minutes}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate some basic stats on these kmer lists.\n",
    "\n",
    "## Bash kmer stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purpose: Generates stats on kmers.\n",
    "# Args:\n",
    "#      input_dir: Input dir for kmer directories (e.g., 9, 15, etc)\n",
    "# Output: Jellyfish kmer stats for each kmer size (subdirectory) for each sample.\n",
    "jellyfish_kmer_stats() {\n",
    "    input_dir=$1\n",
    "    \n",
    "    echo -e \"kmer\\ttotal sizes\" > ${input_dir}/kmer-file-sizes.tsv\n",
    "    for kmer_dir_stats in ${input_dir}/*\n",
    "    do\n",
    "        kmer=`basename ${kmer_dir_stats}`\n",
    "    \n",
    "        # Skip the one non-directory file we create above\n",
    "        if [ -d ${kmer_dir_stats} ]\n",
    "        then\n",
    "            echo -e \"accession\\tkmer_count\\tfile_size_kb\" > ${kmer_dir_stats}/kmer-counts.tsv\n",
    "            for kmer_file in ${kmer_dir_stats}/*.kmer.gz\n",
    "            do\n",
    "                accession=`basename ${kmer_file} .kmer.gz`\n",
    "                kmer_count=`zcat ${kmer_file} | wc -l`\n",
    "                file_size=`du -sk ${kmer_file} | cut -f 1`\n",
    "                echo -e \"$accession\\t${kmer_count}\\t${file_size}\" >> ${kmer_dir_stats}/kmer-counts.tsv\n",
    "            done\n",
    "\n",
    "            total=`du -ch ${kmer_dir_stats}/*.kmer.gz | grep total | sed -e 's/total//'`\n",
    "            echo -e \"${kmer}\\t${total}\" >> ${input_dir}/kmer-file-sizes.tsv\n",
    "        fi\n",
    "    done\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've got our mccortex code defined. Let's run it on a dataset.\n",
    "\n",
    "## Microbial kmer generation\n",
    "\n",
    "Let's first generate a list of all kmers (for different sizes) for the microbial dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir_type=\"microbial\"\n",
    "run_jellyfish \"${input_dir_type}\" \"${input_dir_type}/${kmer_counts_dir}\" \"${kmers_input_sizes}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome. We've generated our kmer list. Let's look at the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls -lh ${input_dir_type}/${kmer_counts_dir}/9 | head -n 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at what data we've genearted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zcat ${input_dir_type}/${kmer_counts_dir}/9/ERR1144976.kmer.gz | head -n 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file contains a list of all kmers along with counts of the kmers in the dataset.\n",
    "\n",
    "Let's now generate some basic stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jellyfish_kmer_stats \"${input_dir_type}/${kmer_counts_dir}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at what we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column -s$'\\t' -t ${input_dir_type}/${kmer_counts_dir}/9/kmer-counts.tsv | head -n 5\n",
    "wc -l ${input_dir_type}/${kmer_counts_dir}/9/kmer-counts.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file contains a list of the true (not estimated) kmers in each file, along with the file sizes. Let's look at the total size of files `jellyfish` made (compressed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat ${input_dir_type}/${kmer_counts_dir}/kmer-file-sizes.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lists the total size of all intermediate files we've generated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metagenomics\n",
    "\n",
    "Let's continue with the metagenomics data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir_type=\"metagenomics\"\n",
    "run_jellyfish \"${input_dir_type}\" \"${input_dir_type}/${kmer_counts_dir}\" \"${kmers_input_sizes}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jellyfish_kmer_stats \"${input_dir_type}/${kmer_counts_dir}\"\n",
    "column -s$'\\t' -t ${input_dir_type}/${kmer_counts_dir}/9/kmer-counts.tsv | head -n 5\n",
    "wc -l ${input_dir_type}/${kmer_counts_dir}/9/kmer-counts.tsv\n",
    "cat ${input_dir_type}/${kmer_counts_dir}/kmer-file-sizes.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On to the human data.\n",
    "\n",
    "# Human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir_type=\"human\"\n",
    "run_jellyfish \"${input_dir_type}\" \"${input_dir_type}/${kmer_counts_dir}\" \"${kmers_input_sizes}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jellyfish_kmer_stats \"${input_dir_type}/${kmer_counts_dir}\"\n",
    "column -s$'\\t' -t ${input_dir_type}/${kmer_counts_dir}/9/kmer-counts.tsv | head -n 5\n",
    "wc -l ${input_dir_type}/${kmer_counts_dir}/9/kmer-counts.tsv\n",
    "cat ${input_dir_type}/${kmer_counts_dir}/kmer-file-sizes.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome. We're all done converting our data into a common format for both BIGSI and HowDeSBT."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
