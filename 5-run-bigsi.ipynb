{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running BIGSI\n",
    "\n",
    "Now let's run BIGSI on our data.\n",
    "\n",
    "First, let's setup some directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir=data-downsampled\n",
    "kmer_dir=kmer-downsampled\n",
    "kmer_counts_dir=kmer-counts-mccortex\n",
    "kmers_input_sizes=\"9\"\n",
    "\n",
    "PROJECT_DIR=`git rev-parse --show-toplevel`\n",
    "cd $PROJECT_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code given below assumes you have the following [conda](https://docs.conda.io/en/latest/) environments setup to install [mccortex](https://github.com/mcveanlab/mccortex) and [bigsi](https://github.com/Phelimb/BIGSI). This can be done with.\n",
    "\n",
    "```bash\n",
    "conda create --name jellyfish jellyfish\n",
    "conda create --name bigsi bigsi\n",
    "```\n",
    "\n",
    "Let's verify these commands exist (and verify versions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jellyfish 2.2.8\n",
      "usage: bigsi-v0.3.1 bloom [-h] [-c CONFIG] ctx outfile\n",
      "\n",
      "Creates a bloom filter from a sequence file or cortex graph.\n",
      "(fastq,fasta,bam,ctx) e.g. index insert ERR1010211.ctx\n",
      "\n",
      "positional arguments:\n",
      "  ctx\n",
      "  outfile\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  -c CONFIG, --config CONFIG\n"
     ]
    }
   ],
   "source": [
    "conda run --name jellyfish jellyfish --version\n",
    "conda run --name bigsi bigsi bloom --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once this step is complete, we need to figure out the maximum number of kmers for our 3 datasets (for passing to `mccortex` to set the hash size). Let's define a bash function for this.\n",
    "\n",
    "## Find max data kmer cardinality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purpose: Gets max kmer cardinality estimates on sequence reads.\n",
    "# Args:\n",
    "#      input_dir: The input directory containing all the kmer counts.\n",
    "#      kmer_size: The kmer_size to find the max.\n",
    "# Output: Prints the the maximum kmer count for the kmer size\n",
    "#         in this directory (files named like `kmer-9.tsv`).\n",
    "get_max_kmer_cardinality() {\n",
    "    input_dir=$1\n",
    "    kmer_size=$2\n",
    "    \n",
    "    cut -f 2 \"${input_dir}/kmer-${kmer_size}.tsv\" | sort -n | tail -n 1 | awk '{print int($1+0.5)}'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test this code out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38109197\n",
      "50876500\n",
      "78652018\n"
     ]
    }
   ],
   "source": [
    "get_max_kmer_cardinality \"microbial/${kmer_dir}\" \"31\"\n",
    "get_max_kmer_cardinality \"human/${kmer_dir}\" \"31\"\n",
    "get_max_kmer_cardinality \"metagenomics/${kmer_dir}\" \"31\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great. Now that we have this setup, we can move to defining a function to count and produce a list of all kmers in the dataset using `mccortex`.\n",
    "\n",
    "## Bash mccortex kmer count function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purpose: Runs mccortex on sequence reads to count kmers.\n",
    "# Args:\n",
    "#      type_dir: The input type directory (e.g., microbial,)\n",
    "#      output_dir: A directory to save the mccortex output into.\n",
    "#      kmer_sizes: The kmer_sizes to run (separated by spaces).\n",
    "#      mccortex_pe_param: The parameter used depening on paired-end/single end data.\n",
    "# Output: mccortex kmer counts in the passed output directory.\n",
    "run_mccortex() {\n",
    "    type_dir=$1\n",
    "    output_dir=$2\n",
    "    kmer_sizes=$3\n",
    "    mccortex_pe_param=$4\n",
    "    \n",
    "    input_dir=${type_dir}/${data_dir}\n",
    "    \n",
    "    threads=1\n",
    "    \n",
    "    rm -rf ${output_dir}\n",
    "    mkdir ${output_dir}\n",
    "    \n",
    "    before=`date +%s`\n",
    "    \n",
    "    for kmer_size in ${kmer_sizes}\n",
    "    do\n",
    "        # Find max kmers\n",
    "        max_kmer=`get_max_kmer_cardinality \"${type_dir}/${kmer_dir}\" \"${kmer_size}\"`\n",
    "        \n",
    "        # Hash size is 10x the max kmers in dataset.\n",
    "        hash_size=`echo \"10*${max_kmer}\" | bc`\n",
    "        \n",
    "        output_dir_kmer=${output_dir}/${kmer_size}\n",
    "        mkdir ${output_dir_kmer}\n",
    "    \n",
    "        #for file in ${input_dir}/*.fastq.gz\n",
    "        for file in ${input_dir}/ERR1144976.fastq.gz ${input_dir}/SRR10512965.fastq.gz\n",
    "        do\n",
    "            accession=`basename ${file} .fastq.gz`\n",
    "\n",
    "            mccortex_out=${output_dir_kmer}/${accession}.ctx\n",
    "            mccortex_log=${output_dir_kmer}/mccortex.count.${accession}.log\n",
    "        \n",
    "            command=\"/usr/bin/time -v mccortex ${kmer_size} build --nkmers ${hash_size} --threads ${threads} --kmer ${kmer_size} \\\n",
    "                --sample ${accession} ${mccortex_pe_param} ${file} ${mccortex_out} 2> ${mccortex_log}.err 1> ${mccortex_log}\"\n",
    "            echo ${command}\n",
    "            conda run --name mccortex ${command}\n",
    "        done\n",
    "    done\n",
    "    \n",
    "    after=`date +%s`\n",
    "    minutes=`echo \"(${after}-${before})/60\" | bc -l`\n",
    "    printf \"Done. Took %0.2f minutes.\" ${minutes}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've got our mccortex code defined. Let's run it on a dataset.\n",
    "\n",
    "## Microbial mccortex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/time -v mccortex 9 build --nkmers 1310850 --threads 1 --kmer 9 --sample ERR1144976 --seqi microbial/data-downsampled/ERR1144976.fastq.gz microbial/kmer-counts-mccortex/9/ERR1144976.ctx 2> microbial/kmer-counts-mccortex/9/mccortex.count.ERR1144976.log.err 1> microbial/kmer-counts-mccortex/9/mccortex.count.ERR1144976.log\n",
      "/usr/bin/time -v mccortex 9 build --nkmers 1310850 --threads 1 --kmer 9 --sample SRR10512965 --seqi microbial/data-downsampled/SRR10512965.fastq.gz microbial/kmer-counts-mccortex/9/SRR10512965.ctx 2> microbial/kmer-counts-mccortex/9/mccortex.count.SRR10512965.log.err 1> microbial/kmer-counts-mccortex/9/mccortex.count.SRR10512965.log\n",
      "Done. Took 0.50 minutes."
     ]
    }
   ],
   "source": [
    "input_dir_type=\"microbial\"\n",
    "run_mccortex ${input_dir_type} \"${input_dir_type}/${kmer_counts_dir}\" \"${kmers_input_sizes}\" \"--seqi\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright. It's all finished. Let's look at some of the output files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 3.3M\n",
      "-rw-r--r-- 1 apetkau grp_apetkau 1.6M Dec 10 12:11 ERR1144976.ctx\n",
      "-rw-r--r-- 1 apetkau grp_apetkau    0 Dec 10 12:11 mccortex.count.ERR1144976.log\n",
      "-rw-r--r-- 1 apetkau grp_apetkau 4.0K Dec 10 12:11 mccortex.count.ERR1144976.log.err\n",
      "-rw-r--r-- 1 apetkau grp_apetkau    0 Dec 10 12:11 mccortex.count.SRR10512965.log\n",
      "kmer\ttotal size\n",
      "9\t3.3M\t\n"
     ]
    }
   ],
   "source": [
    "ls -lh ${input_dir_type}/${kmer_counts_dir}/9 | head -n 5\n",
    "echo -e \"kmer\\ttotal size\"\n",
    "for kmer in ${kmers_input_sizes}\n",
    "do\n",
    "    size=`du -ch ${input_dir_type}/${kmer_counts_dir}/${kmer}/*.ctx | grep total | sed -e 's/total//'`\n",
    "    echo -e \"${kmer}\\t${size}\"\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat: microbial/kmer-counts-mccortex/9/jellyfish.ERR1144976.log.err: No such file or directory\n"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "execution_count": 22,
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "cat microbial/${kmer_counts_dir}/9/jellyfish.ERR1144976.log.err"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
